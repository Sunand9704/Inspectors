'use strict';

// This script uploads images from frontend/uploads/** to Cloudinary
// using the existing Cloudinary service and writes the secure URLs
// into frontend/src/images.js in a clear, reusable structure.

const path = require('path');
const fs = require('fs');
const { glob } = require('glob');
const cloudinaryService = require('../services/cloudinary');


async function getIndustryFolders(rootDir) {
  const entries = await fs.promises.readdir(rootDir, { withFileTypes: true });
  return entries.filter(e => e.isDirectory()).map(e => e.name);
}

function toServiceAndSub(folderName) {
  // We place everything under serviceType = 'industries'
  // and use the folder name as subService
  return { serviceType: 'industries', subService: folderName };
}

function sanitizeKey(name) {
  // Keep a readable key: lowercase, spaces and special chars to dashes
  return name
    .toLowerCase()
    .replace(/[^a-z0-9]+/g, '-')
    .replace(/^-+|-+$/g, '');
}

async function uploadFolderImages(folderAbsPath, folderName) {
  const pattern = path.join(folderAbsPath, '*.{png,jpg,jpeg,webp}');
  const files = await glob(pattern.replace(/\\/g, '/'), { nocase: true });
  const { serviceType } = toServiceAndSub(folderName);
  const safeSubService = sanitizeKey(folderName);

  const uploads = [];
  for (const file of files) {
    const imageName = path.basename(file);
    const result = await cloudinaryService.uploadImage(
      file,
      serviceType,
      safeSubService,
      null
    );
    uploads.push({
      file: imageName,
      url: result.url,
      publicId: result.public_id
    });
  }
  return uploads;
}

function buildImagesJsContent(map) {
  // map structure: { [folderName]: [{ file, url, publicId }, ...] }
  const lines = [];
  lines.push('// Auto-generated by backend/src/scripts/upload-frontend-images-to-cloudinary.js');
  lines.push('// Do not edit manually. Re-run the script to update.');
  lines.push('');
  lines.push('export const industryImages = {');
  for (const [folderName, uploads] of Object.entries(map)) {
    const key = sanitizeKey(folderName);
    lines.push(`  "${key}": {`);
    lines.push(`    name: ${JSON.stringify(folderName)},`);
    lines.push('    images: [');
    for (const u of uploads) {
      lines.push(`      { file: ${JSON.stringify(u.file)}, url: ${JSON.stringify(u.url)}, publicId: ${JSON.stringify(u.publicId)} },`);
    }
    lines.push('    ]');
    lines.push('  },');
  }
  lines.push('};');
  lines.push('');
  lines.push('export default industryImages;');
  lines.push('');
  return lines.join('\n');
}

async function main() {
  const repoRoot = path.resolve(__dirname, '../../..');
  const frontendUploadsDir = path.join(repoRoot, 'frontend', 'uploads');
  const imagesJsPath = path.join(repoRoot, 'frontend', 'src', 'images.js');

  // Validate source directory exists
  try {
    await fs.promises.access(frontendUploadsDir, fs.constants.R_OK);
  } catch (err) {
    throw new Error(`Uploads directory not found: ${frontendUploadsDir}`);
  }

  const folders = await getIndustryFolders(frontendUploadsDir);
  const resultMap = {};

  for (const folder of folders) {
    const folderAbs = path.join(frontendUploadsDir, folder);
    const uploads = await uploadFolderImages(folderAbs, folder);
    resultMap[folder] = uploads;
  }

  // Ensure target directory exists
  await fs.promises.mkdir(path.dirname(imagesJsPath), { recursive: true });
  const content = buildImagesJsContent(resultMap);
  await fs.promises.writeFile(imagesJsPath, content, 'utf8');

  // eslint-disable-next-line no-console
  console.log(`Wrote ${imagesJsPath}`);
}

main().catch((err) => {
  // eslint-disable-next-line no-console
  console.error(err);
  process.exit(1);
});


